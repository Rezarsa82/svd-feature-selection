{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import time\n",
    "from sklearn.feature_selection import mutual_info_classif, RFE\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1567, 590)\n",
      "Labels shape: (1567, 2)\n",
      "Constant columns to remove: 116\n",
      "Shape after removal: (1567, 474)\n",
      "NaN values before imputation: 41136\n",
      "NaN values after imputation: 0\n",
      "Final data shape: (1567, 474)\n",
      "Data range - Min: -37.9235, Max: 39.5727\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "\n",
    "if not os.path.exists('secom.data'):\n",
    "    print(\"Downloading SECOM dataset...\")\n",
    "    urlretrieve('https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data', 'secom.data')\n",
    "    urlretrieve('https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom_labels.data', 'secom_labels.data')\n",
    "\n",
    "data = pd.read_csv('secom.data', sep='\\s+', header=None)\n",
    "labels = pd.read_csv('secom_labels.data', sep='\\s+', header=None)\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "constant_mask = data.nunique() == 1\n",
    "constant_cols = data.columns[constant_mask]\n",
    "print(f\"Constant columns to remove: {len(constant_cols)}\")\n",
    "\n",
    "if len(constant_cols) > 0:\n",
    "    data = data.drop(columns=constant_cols)\n",
    "\n",
    "print(f\"Shape after removal: {data.shape}\")\n",
    "\n",
    "print(f\"NaN values before imputation: {data.isna().sum().sum()}\")\n",
    "data = data.apply(lambda x: x.fillna(x.median()), axis=0)\n",
    "print(f\"NaN values after imputation: {data.isna().sum().sum()}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "data_scaled = pd.DataFrame(data_scaled, columns=data.columns)\n",
    "\n",
    "print(f\"Final data shape: {data_scaled.shape}\")\n",
    "print(f\"Data range - Min: {data_scaled.min().min():.4f}, Max: {data_scaled.max().max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 MI features selected in 2.37 seconds\n",
      "MI scores range: 0.0000 to 0.0281\n"
     ]
    }
   ],
   "source": [
    "X = data_scaled\n",
    "y = labels.iloc[:, 0]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "mi_scores = mutual_info_classif(X, y, random_state=42)\n",
    "top_20_mi_idx = np.argsort(mi_scores)[-20:][::-1]\n",
    "top_20_mi_features = X.columns[top_20_mi_idx].tolist()\n",
    "\n",
    "mi_time = time.time() - start_time\n",
    "print(f\"Top 20 MI features selected in {mi_time:.2f} seconds\")\n",
    "print(f\"MI scores range: {mi_scores.min():.4f} to {mi_scores.max():.4f}\")\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# estimator = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# rfe = RFE(estimator=estimator, n_features_to_select=20)\n",
    "# rfe.fit(X, y)\n",
    "\n",
    "# rfe_time = time.time() - start_time\n",
    "# top_20_rfe_features = X.columns[rfe.support_].tolist()\n",
    "\n",
    "# print(f\"RFE completed in {rfe_time:.2f} seconds\")\n",
    "# print(f\"Selected {len(top_20_rfe_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast RFE completed in 27.98 seconds\n",
      "Selected 20 features\n"
     ]
    }
   ],
   "source": [
    "# Stop current execution and run this instead with different configuration\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "estimator = RandomForestClassifier(n_estimators=30, max_depth=5, random_state=42)\n",
    "rfe = RFE(estimator=estimator, n_features_to_select=20, step=5)\n",
    "rfe.fit(X, y)\n",
    "\n",
    "rfe_time = time.time() - start_time\n",
    "top_20_rfe_features = X.columns[rfe.support_].tolist()\n",
    "\n",
    "print(f\"Fast RFE completed in {rfe_time:.2f} seconds\")\n",
    "print(f\"Selected {len(top_20_rfe_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, Sigma, Vt = np.linalg.svd(data_scaled, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized SVD scores range: 0.006444 to 0.052291\n",
      "\n",
      "Top 5 features with normalized scores:\n",
      "  Feature 303: 0.052291\n",
      "  Feature 168: 0.051149\n",
      "  Feature 556: 0.048934\n",
      "  Feature 550: 0.048922\n",
      "  Feature 132: 0.048786\n"
     ]
    }
   ],
   "source": [
    "def feature_scores_svd_normalized(Vt, Sigma, k=20):\n",
    "    k = min(k, len(Sigma))\n",
    "    Vt_k = Vt[:k, :]\n",
    "    Sigma_k = Sigma[:k]\n",
    "    \n",
    "    Sigma_norm = Sigma_k / Sigma_k.sum()\n",
    "    \n",
    "    scores = np.sum((Sigma_norm[:, np.newaxis]) * np.abs(Vt_k), axis=0)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "svd_scores_norm = feature_scores_svd_normalized(Vt, Sigma, k=20)\n",
    "top_20_svd_idx_norm = np.argsort(svd_scores_norm)[-20:][::-1]\n",
    "top_20_svd_features_norm = data_scaled.columns[top_20_svd_idx_norm].tolist()\n",
    "\n",
    "print(f\"Normalized SVD scores range: {svd_scores_norm.min():.6f} to {svd_scores_norm.max():.6f}\")\n",
    "print(f\"\\nTop 5 features with normalized scores:\")\n",
    "for i in range(5):\n",
    "    print(f\"  Feature {top_20_svd_features_norm[i]}: {svd_scores_norm[top_20_svd_idx_norm[i]]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
